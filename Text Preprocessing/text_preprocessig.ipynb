{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb7c9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     text  num\n",
      "0            Movies is Very easy<br></br>   10\n",
      "1  <html>!@ movies is very bad. very bad    20\n",
      "2                        Movies are good    30\n",
      "3      <span>movies are excellent?</span>   40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data={\n",
    "    \"text\":[\"Movies is Very easy<br></br>\",\"<html>!@ movies is very bad. very bad \",\"Movies are good \",\"<span>movies are excellent?</span>\"],\n",
    "    \"num\":[10,20,30,40],\n",
    "    \n",
    "}\n",
    "df=pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a17962db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     text  num\n",
      "0            movies is very easy<br></br>   10\n",
      "1  <html>!@ movies is very bad. very bad    20\n",
      "2                        movies are good    30\n",
      "3      <span>movies are excellent?</span>   40\n"
     ]
    }
   ],
   "source": [
    "#lowercasing\n",
    "df['text']=df['text'].str.lower()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b7e742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove html tags\n",
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern=re.compile('<.*?>')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c85f8a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               text  num\n",
      "0               movies is very easy   10\n",
      "1  !@ movies is very bad. very bad    20\n",
      "2                  movies are good    30\n",
      "3             movies are excellent?   40\n"
     ]
    }
   ],
   "source": [
    "df['text']=df['text'].apply(remove_html_tags)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ca4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove URLS\n",
    "def remove_url(text):\n",
    "    pattern=re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f828c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am learning this from  from \n"
     ]
    }
   ],
   "source": [
    "text1=\"i am learning this from https://www.youtube.com/watch?v=6C0sLtw5ctc from www.google.com\"\n",
    "text1=remove_url(text1)\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa6ccd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation\n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "514bb5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "punc=string.punctuation\n",
    "def remove_punc(text):\n",
    "    return text.translate(str.maketrans('','',punc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "631a39b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " movies is very bad very bad\n"
     ]
    }
   ],
   "source": [
    "t=\"!@ movies is very bad. very bad\"\n",
    "t=remove_punc(t)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f67c3391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            text  num\n",
      "0            movies is very easy   10\n",
      "1   movies is very bad very bad    20\n",
      "2               movies are good    30\n",
      "3           movies are excellent   40\n"
     ]
    }
   ],
   "source": [
    "df['text']=df['text'].apply(remove_punc)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6043d314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'invalid text are you baker excellent'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Spelling Correction\n",
    "from textblob import TextBlob\n",
    "\n",
    "incorrect_text=\"invaild text aree yuo bacer exceelent\"\n",
    "textBlb=TextBlob(incorrect_text)\n",
    "\n",
    "textBlb.correct().string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44dca59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a278a0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x=new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fc6bd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                text  num\n",
      "0      movies   easy   10\n",
      "1  movies   bad  bad   20\n",
      "2       movies  good   30\n",
      "3  movies  excellent   40\n"
     ]
    }
   ],
   "source": [
    "df['text']=df['text'].apply(remove_stopwords)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09acd205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'done', 'ph.D.', 'in', 'A.I', '.']\n",
      "['we', \"'re\", 'here', 'to', 'help', '!', 'mail', 'me', 'at', 'abc', '@', 'gmail.com']\n",
      "['A', '5km', 'ride', 'cost', '$', '10.50']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "\n",
    "txt1=\"I done ph.D. in A.I.\"\n",
    "txt2=\"we're here to help! mail me at abc@gmail.com\"\n",
    "txt3='A 5km ride cost $10.50'\n",
    "\n",
    "print(word_tokenize(txt1))\n",
    "print(word_tokenize(txt2))\n",
    "print(word_tokenize(txt3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2922d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I done ph.D. in A.I.',\n",
       " \"we're here to help!\",\n",
       " 'mail me at abc@gmail.com.',\n",
       " 'A 5km ride cost $10.50']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt=\"I done ph.D. in A.I. we're here to help! mail me at abc@gmail.com. A 5km ride cost $10.50\"\n",
    "sent_tokenize(txt)\n",
    "#we can also use spacy\n",
    "#import spacy\n",
    "#nlp=spacy.load('en_core_web_sm')\n",
    "#convert sentence in doc\n",
    "#doc=nlp(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "931293cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps=PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join(ps.stem(word) for word in text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ca5675e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=\"walk walking walked walks\"\n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd5236d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probabl i will goe for movi watch through walk'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1=\"probably i will goes for movie watching through walking\"\n",
    "stem_words(sample1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
